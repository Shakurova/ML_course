# ML_course
Here will be homeworks for Machine Learning course at NRU HSE 

<b>HW 1</b>

1. Загрузить titanic.csv. Нарисовать диаграммы (гистограммы/круговые/...), по которым можно будет сравнить 1) вероятность выжить для мужчин и женщин, 2) вероятность выжить для пассажиров разных социально-экономических классов (Pclass), 3) стоимость билета в зависимости от социально-экономического класса. Написать, что вам удалось узнать из этих диаграмм (например, «для пассажира 1 класса вероятность выжить составила XX% и оказалась выше, чем у пассажира 2 класса (YY%)»; чем больше информации вы сможете извлечь из диаграмм, тем лучше)


2. А теперь нарисуем два предиктора на одной диаграмме. Нарисовать гистограмму, описывающую среднюю вероятность выжить в зависимости от пола и соц. статуса. Например, это может быть гистограмма с тремя группами столбцов (разделение по соц.статусу), в которой высота столбца соответствует среднему числу выживших, а цвет столбца обозначает пол пассажиров. Снова интерпретировать результаты (Например, какова вероятность выжить женщине из первого класса?). Записать любые два утверждения в виде формул (нужно вспомнить, что такое совместная и/или условная вероятность).


3. Почистите данные так, как считаете нужным (не забывайте про коварную переменную Sex; постарайтесь не удалять строки). Extra: сможете ли вы использовать не 4 столбца, а больше? Например, кажется, что если ребёнок ехал с братом/сестрой, то их не разлучат, а посадят вместе в шлюпку, и они выживут...


4. Разделить данные на обучающую и проверочную выборки (или использовать кросс-валидацию). Будем строить дерево решений. Нужно выбрать параметр модели, который, на ваш взгляд, может повлиять на результат, и выбрать для него возможные значения. Прокомментировать свой выбор. Изменяя в цикле значения параметра, посчитать для каждого случая точноть, полноту, F-меру (может быть, другие метрики?). Изобразить результаты на диаграмме/-ах. Интерпретировать результаты. Нарисовать лучшее дерево.


5. Extra: варьировать не в цикле, а использовать grid search.
Super–duper-Extra: построить ROC-кривую и написать свою интерпретацию того, что эта диаграмма говорит о модели.


6. Проделать аналогичные операции для модели Random Forest. Сравнить результаты.

<b>HW 2</b>

1. Проверить, сбалансирован ли датасет (может быть, наблюдений одного класса слишком много?).
Какие результаты покажет dummy classifier, который будет всем новым наблюдениям присваивать класс ham?
Насколько плохо такое решение для задачи определения спама?
Грубое решение - включить в training set только необходимое число наблюдений (примерно поровну spam и ham).
Нормализовать тексты и обучить байесовскую модель (bag of words). Проверить, как влияют на результат:
1) разная токенизация: в одном случае знаки препинания удалять, в другом — считать их токенами;
2) лемматизация (отсутствие лемматизации, стемминг, лемматизация; инструменты можно использовать любые, например, nltk.stem);
3) удаление стоп-слов, а также пороги минимальной и максимальной document frequency;
4) векторизация документов (CountVectorizer vs. TfIdfVectorizer);
5) что-нибудь ещё?
При оценке классификатора обратите внимание на TP и FP.

Extra: ограничив количество наблюдений ham в обучающей выборке, мы игнорируем довольно много данных. 1)
В цикле: случайно выбрать нужное число писем ham и сконструировать сбалансированную выборку, построить классификатор,
 оценить и записать результат; в итоге результаты усреднить. 2) поможет ли параметр class prior probability?

2. Сравнить результаты байесовского классификатора, решающего дерева и RandomForest. Помимо стандартных метрик
оценки качества модели, необходимо построить learning curve, ROC-curve, classification report и интерпретировать эти результаты.

3. А что, если в качестве предикторов брать не количество вхождений слов, а конструировать специальные признаки?
Прежде всего, необходимо разделить таблицу на training set и test set в соотношении 80:20, test set не открывать до
этапа оценки модели. С помощью pandas проверить, отличаются ли перечисленные ниже параметры (иможно придумать другие)
для разных классов (spam/ham), и собрать матрицу признаков для обучения. Примеры признаков: длина сообщения,
количество букв в ВЕРХНЕМ РЕГИСТРЕ, восклицательных знаков, цифр, запятых, каких-то конкретных слов (для этого
можно построить частотный словарь по сообщениям каждого класса). Прокомментировать свой выбор. Векторизовать
документы и построить классификатор. Оценить модель на проверочной выборке.

